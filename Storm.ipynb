{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install knowledge-storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from knowledge_storm import STORMWikiRunnerArguments, STORMWikiRunner, STORMWikiLMConfigs\n",
    "from knowledge_storm.lm import OpenAIModel\n",
    "from knowledge_storm.rm import YouRM\n",
    "\n",
    "lm_configs = STORMWikiLMConfigs()\n",
    "openai_kwargs = {\n",
    "    'api_key': os.getenv(\"OPENAI_API_KEY\"),\n",
    "    'temperature': 1.0,\n",
    "    'top_p': 0.9,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must supply ydc_api_key or set environment variable YDC_API_KEY",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check out the STORMWikiRunnerArguments class for more configurations.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m STORMWikiRunnerArguments(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m rm \u001b[38;5;241m=\u001b[39m \u001b[43mYouRM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mydc_api_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYDC_API_KEY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_top_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m runner \u001b[38;5;241m=\u001b[39m STORMWikiRunner(engine_args, lm_configs, rm)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/knowledge_storm/rm.py:21\u001b[0m, in \u001b[0;36mYouRM.__init__\u001b[0;34m(self, ydc_api_key, k, is_valid_source)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(k\u001b[38;5;241m=\u001b[39mk)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ydc_api_key \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYDC_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must supply ydc_api_key or set environment variable YDC_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ydc_api_key:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mydc_api_key \u001b[38;5;241m=\u001b[39m ydc_api_key\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must supply ydc_api_key or set environment variable YDC_API_KEY"
     ]
    }
   ],
   "source": [
    "# STORM is a LM system so different components can be powered by different models to reach a good balance between cost and quality.\n",
    "# For a good practice, choose a cheaper/faster model for `conv_simulator_lm` which is used to split queries, synthesize answers in the conversation.\n",
    "# Choose a more powerful model for `article_gen_lm` to generate verifiable text with citations.\n",
    "gpt_35 = OpenAIModel(model='gpt-3.5-turbo', max_tokens=500, **openai_kwargs)\n",
    "gpt_4 = OpenAIModel(model='gpt-4o', max_tokens=3000, **openai_kwargs)\n",
    "lm_configs.set_conv_simulator_lm(gpt_35)\n",
    "lm_configs.set_question_asker_lm(gpt_35)\n",
    "lm_configs.set_outline_gen_lm(gpt_4)\n",
    "lm_configs.set_article_gen_lm(gpt_4)\n",
    "lm_configs.set_article_polish_lm(gpt_4)\n",
    "# Check out the STORMWikiRunnerArguments class for more configurations.\n",
    "engine_args = STORMWikiRunnerArguments(...)\n",
    "rm = YouRM(ydc_api_key=os.getenv('YDC_API_KEY'), k=engine_args.search_top_k)\n",
    "runner = STORMWikiRunner(engine_args, lm_configs, rm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
